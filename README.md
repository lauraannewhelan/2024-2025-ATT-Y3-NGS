# ðŸ§¬ Lab: Next-Generation Sequencing Analysis 1 & 2 ðŸ§¬

Across these two labs, we will guide you through the essential steps involved in processing high-quality reads from Next-Generation Sequencing (NGS) and mapping them to a reference genome. You will learn how to perform quality control on short-read NGS data, map high-quality reads, and understand the post-mapping processes necessary for effective variant calling and annotation. 

By the end of this tutorial, you will have a comprehensive understanding of the entire workflow, including:
- Data preparation
- Quality control
- Read mapping
- Generation of variant databases

## Learning Outcomes

### NGS Analysis 1
- Review the structure and origin of sequencing reads.
- Outline the file formats in which reads and mapped reads are stored.
- Describe the basic quality control steps necessary for processing read data.
- Describe the process of read mapping.

### NGS Analysis 2
- Understand the motivation to identify variants from NGS data in a clinical setting.
- Describe the GATK best practices for variant identification.
- Describe the file formats in which variants are stored.
- Outline the primary measures of variant quality control.

---

# ðŸ›  Before You Begin

1. **Create a Galaxy user account** using your RCSI email: [Sign up here](https://usegalaxy.org/login/start?redirect=None).
2. **Download the **data_files** folder** from [this link](https://rcsicampus-my.sharepoint.com/:f:/g/personal/laurawhelan_rcsi_com/EkI2pyMKZNxOjeDJOtqnB9EB3L5pV0j_TEIivBL5suTB7A?e=x4cKab).
3. **Create a new **history**** within Galaxy named **ATT_NGS_LAB**.

![Create New History](https://github.com/user-attachments/assets/4d6c3652-22f2-4612-ad62-ae78b5c13c4b)

> **Note:** I have **pre-made** all the files for you. You're going to perform all the steps to make these files, but some of these steps take a long time computationally. That's why we have pre-made files ready for you, similar to a cooking show â€” *hereâ€™s one we made earlier!*

---

# ðŸ§¬ Lab: Next-Generation Sequencing Analysis 1 ðŸ§¬

# Let's Get Started
> **There will be a video to follow on screen!**

## Data Preparation

### Steps
1. **Upload your data** to your **ATT_NGS_LAB** history.
2. **Check dataset types**: Ensure the datasets have their datatypes assigned correctly to `fastqsanger.gz`. Fix any missing or incorrect datatype assignments.
3. **Tag datasets** as #father, #mother, or #child for the **.gz** files.

    - To tag a dataset:
      - Click on the dataset to expand it.
      - Click on **Add Tags**.
      - Add the appropriate tag (tags starting with `#` will propagate to tool outputs).
      - Press Enter.
      - Check that the tag appears below the dataset name.

4. **Update file type and genome build** for all **.gz** files:
   - **Type**: fasta
   - **Genome**: Human Feb. 2009 (GRCh37/hg19) (hg19)

---

## Quality Control

This step is to identify any possible issues with the raw sequencing read data before starting the analysis.

### Steps
1. **Run FastQC** on each of your six `.fastq` datasets.
2. **Use MultiQC** to aggregate the raw FastQC data into one comprehensive report.
3. **Inspect the MultiQC output** for potential issues.

---

## Read Mapping

After confirming that the quality of the input data is acceptable, itâ€™s time to map the sequencing reads to the reference genome.

### Steps

1. **Map the fatherâ€™s reads** using BWA-MEM (Galaxy version 0.7.17.2):
   - **Reference Genome**: Use a built-in genome index (Human: hg19).
   - **Read Type**: Paired-end.
   - **First Set of Reads**: Forward reads (R1) of the father.
   - **Second Set of Reads**: Reverse reads (R2) of the father.
   - **Read Group Information**: Set read groups.
     - **Read Group ID**: 000
     - **Sample Name**: father

2. **Map the motherâ€™s reads** using BWA-MEM with the same parameters, except:
   - **Read Group ID**: 001
   - **Sample Name**: mother

3. **Map the childâ€™s reads** using BWA-MEM with the same parameters, except:
   - **Read Group ID**: 002
   - **Sample Name**: proband

> **Note:** Read mapping is step that can take a considerable amount of time, so for the next steps we'll use pre made bam files for the next steps. 

---

## Mapped Reads Postprocessing

Earlier, you should have uploaded three `.bam` files â€” one for the father, one for the mother, and one for the proband. These are exactly what would be produced by BWA-MEM.

### Steps

1. **Tag datasets** as `#father`, `#mother`, or `#child` for the `.bam` files:
   
   - Click on the dataset to expand it.
   - Click on **Add Tags**.
   - Add the appropriate tag (tags starting with `#` will propagate to tool outputs).
   - Press Enter.
   - Check that the tag appears below the dataset name.

2. **Update database/build** for all `.bam` files:
   
   - Click the desired datasetâ€™s name to expand it.
   - Click on the **?** next to the database indicator:
   
     ![Screenshot](https://github.com/user-attachments/assets/3e10afc7-6148-4433-b393-41f945126ada)
   
   - In the central panel, change the **Database/Build** field.
   - Select your desired database key from the dropdown list: `Human Feb. 2009 (GRCh37/hg19) (hg19)`.
   - Click the **Save** button.

3. **Filtering** on mapped reads properties:

   Run **Samtools view** with the following parameters (leave non-mentioned ones at their defaults):

   - **SAM/BAM/CRAM data set**: Select all three mapped reads datasets of the family trio (outputs of the BWA-MEM tool).
   - **What would you like to look at?**: A filtered/subsampled selection of reads
   - **Configure filters**: **Exclude reads with any of the following flags set**: Read is unmapped and Mate is unmapped

4. **Removing duplicate reads**

   Run **RmDup** with the following parameters:
    - **param-files BAM file**: all 3 filtered reads datasets; the outputs of Samtools view
    - **Is this paired-end or single end data**: BAM is paired-end
    - **Treat as single-end**: No
  
## Variant Calling

Now is the fun part! We're actually going to find variants in our patient vs the human reference genome - sort of like spot the difference. 

### Steps

FreeBayes is a Bayesian genetic variant detector designed to find small polymorphisms, specifically SNPs (single-nucleotide polymorphisms), indels (insertions and deletions), MNPs (multi-nucleotide polymorphisms), and complex events (composite insertion and substitution events) smaller than the length of a short-read sequencing alignment.

1. **Generating FreeBayes calls**

    Run  **FreeBayes** with the following paramaters:
    -  **Choose the source for the reference genome**: Locally cached
    -  **Run in batch mode?**: Merge output VCFs
    -  **param-files **BAM dataset(s)**: all three mapped reads datasets of the family trio; the outputs of RmDup
    -  **Using reference genome**: Human: hg19 (or a similarly named option)
    -  **Limit variant calling to a set of regions?**: Do not limit
    -  **Choose parameter selection level**: 1. Simple diploid calling
  
You have created you first multisample VCF file, one of the most complicated file formats in bioinformatics. For every variant detected in at least one of your samples, this tab-separated format uses a single line to store all information about the variant. This includes but is not limited to:

- the position of the variant in the genome (with respect to the reference genome used for the analysis)
- the nature of the variant (the actual sequence change associated with it)
- the detected genotype of every sample at the variant position
- measures of the reliability of the variant call and of all individual genotype calls

# âœ… That's the end of our first NGS lab!

---

# ðŸ§¬ Lab: Next-Generation Sequencing Analysis 2 ðŸ§¬

At the end of our last lab we created a multiple sample VCF file - now it's time to do some postprocessing and also annotate the file to make it easier for us to read. 

# Let's Get Started
> **There will be a video to follow on screen!**

# #Inspect the VCF output produced by FreeBayes

### Steps
**Display the VCF dataset**:
- Click the galaxy-eye icon next to the VCF dataset generated by FreeBayes to display its contents.
- VCF is a tabular plain text format though its information density makes it complicated to understand.

### Question 
Can you locate at least some of the above-listed information in the dataset?
Hints:
- Lines starting with ## are comment lines explaining the content of the file.
- Diploid genotypes at biallelic sites are encoded using 0/0, 0/1 and 1/1 to represent homozygous reference, heterozygous and homozygous variant states, respectively.

## Inspect the VCF output produced by FreeBayes

### Steps

1. Run **bcftools norm** with the following parameters:
- **VCF/BCF Data**: the VCF output of FreeBayes tool
- **Choose the source for the reference genome**: Use a built-in genome
- **Reference genome**: Human: hg19 (or a similarly named option)
- **When any REF allele does not match the reference genome base**: ignore the problem (-w)
- **Atomize**: No
- **Left-align and normalize indels?**: Yes
- **Perform deduplication for the folowing types of variant records**: do not deduplicate any records (Freebayes is not producing any duplicate calls).
- **~multiallelics**: split multiallelic sites into biallelic records (-)
    - **split the following variant types**: both
- **output_type**: uncompressed VCF

## Variant annotation and reporting

A list of variants detected in a set of samples is a start, but to discover biologically or clinically relevant information in it is almost impossible without some additional tools and data. In particular, the variants in the list need to be:
- prioritized with respect to their potential relevance for the biological / clinical phenotype that is studied

    Even with exome sequencing, only a fraction of the detected variants will have a clear impact on the function of a protein (many variants will introduce silent mutations, or reside in intronic regions still covered by     the exome-enriched sequencing data). Of these, many will have been observed before in healthy individuals arguing against them playing an important role in an adverse phenotype.

- filtered based on the inheritance pattern expected for a causative variant

    A multisample VCF file records the most likely genotypes of all samples at every variant site. Knowing which individuals (samples) are affected by a phenotype we can exclude variants with inheritance patterns that are     incompatible with the observed inheritance of the phenotype.

- reported in a more human-friendly form

    While the VCF format can be used to encode all relevant information about any variant, it is hard for humans to parse that information.
    
    Ideally, one would like to generate simpler reports for any set of filtered and prioritized variants.
